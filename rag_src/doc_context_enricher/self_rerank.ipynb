{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpmdlFaYn-ox"
      },
      "outputs": [],
      "source": [
        "from base.doc_context_enricher import BaseContextEnricher\n",
        "from typing import List\n",
        "\n",
        "class SelfRerank(BaseContextEnricher):\n",
        "    \"\"\"\n",
        "    This class re-ranks the documents using the LLM.\n",
        "    For each document, we ask the LLM to rate its relevance 0 to 1,\n",
        "    and then return the top-k documents with  highest score.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm, top_k: int = 5):\n",
        "        self.llm = llm\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def enrich(self, docs: List[str]) -> List[str]:\n",
        "        ranked_docs = []\n",
        "\n",
        "        for doc in docs:\n",
        "            prompt = f\"Give a relevance score (0 to 1) for the following doc:\\n\\n{doc}\"\n",
        "            try:\n",
        "                score = float(self.llm.generate(prompt))\n",
        "            except:\n",
        "                score = 0.5  # default score if LLM fails\n",
        "            ranked_docs.append((score, doc))\n",
        "\n",
        "        # sort by score in descending order\n",
        "        ranked_docs.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "        # return only the document part from the top-k tuples\n",
        "        return [doc for _, doc in ranked_docs[:self.top_k]]\n"
      ]
    }
  ]
}